{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import uuid\n",
    "import time\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMAGES_PATH = os.path.join('images')\n",
    "labels = ['drowsy', 'awake']\n",
    "number_imgs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "for label in labels:\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "    for img_num in range(number_imgs):\n",
    "        print('Collecting images for {}, image number {}'.format(label, img_num))\n",
    "        \n",
    "    \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "    \n",
    "        imgname = os.path.join(IMAGES_PATH, label+'.'+str(uuid.uuid1())+'.jpg')\n",
    "        \n",
    "        \n",
    "        cv2.imwrite(imgname, frame)\n",
    "        \n",
    "        \n",
    "        cv2.imshow('Image Collection', frame)\n",
    "        \n",
    "    \n",
    "        time.sleep(2)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_images(image_path, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for img_name in os.listdir(image_path):\n",
    "        img = cv2.imread(os.path.join(image_path, img_name))\n",
    "        img = cv2.resize(img, (224, 224))  \n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "closed_eye_images, closed_eye_labels = load_and_preprocess_images(CLOSED_EYES_PATH, 0)\n",
    "open_eye_images, open_eye_labels = load_and_preprocess_images(OPEN_EYES_PATH, 1)\n",
    "\n",
    "images = closed_eye_images + open_eye_images\n",
    "labels = closed_eye_labels + open_eye_labels\n",
    "\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "images, labels = shuffle(images, labels, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def split_data(image_paths, labels, train_size=0.8):\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        image_paths, labels, train_size=train_size, stratify=labels, random_state=42\n",
    "    )\n",
    "    return train_paths, val_paths, train_labels, val_labels\n",
    "\n",
    "def move_files(image_paths, labels, dest_folder):\n",
    "    for image_path, label in zip(image_paths, labels):\n",
    "        \n",
    "        label_file = os.path.splitext(os.path.basename(image_path))[0] + '.txt'\n",
    "        label_path = os.path.join(LABELS_PATH, label_file)\n",
    "\n",
    "        \n",
    "        image_dest_folder = os.path.join(dest_folder, 'images', label)\n",
    "        label_dest_folder = os.path.join(dest_folder, 'labels', label)\n",
    "        \n",
    "        os.makedirs(image_dest_folder, exist_ok=True)\n",
    "        os.makedirs(label_dest_folder, exist_ok=True)\n",
    "\n",
    "        \n",
    "        shutil.copy(image_path, os.path.join(image_dest_folder, os.path.basename(image_path)))\n",
    "        shutil.copy(label_path, os.path.join(label_dest_folder, label_file))\n",
    "\n",
    "\n",
    "CLOSED_EYES_PATH = os.path.join('images', 'drowsy')\n",
    "OPEN_EYES_PATH = os.path.join('images', 'awake')\n",
    "LABELS_PATH = os.path.join('images', 'labels')  \n",
    "\n",
    "\n",
    "image_paths = [os.path.join(CLOSED_EYES_PATH, f) for f in os.listdir(CLOSED_EYES_PATH)] + \\\n",
    "              [os.path.join(OPEN_EYES_PATH, f) for f in os.listdir(OPEN_EYES_PATH)]\n",
    "labels = ['closed' for _ in range(len(os.listdir(CLOSED_EYES_PATH)))] + \\\n",
    "         ['open' for _ in range(len(os.listdir(OPEN_EYES_PATH)))]\n",
    "\n",
    "\n",
    "train_paths, val_paths, train_labels, val_labels = split_data(image_paths, labels)\n",
    "\n",
    "\n",
    "move_files(train_paths, train_labels, 'dataset/train')\n",
    "move_files(val_paths, val_labels, 'dataset/val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd yolov5 && python train.py --img 320 --batch 10 --epochs 200 --data dataset.yaml --weights yolov5s.pt --workers 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "\n",
    "def play_alert_sound():\n",
    "    playsound('alert.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=r'yolov5\\runs\\train\\exp\\weights\\best.pt')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "drowsy_start_time = None  \n",
    "DROWSY_THRESHOLD = 8  \n",
    "\n",
    "alert_sound_path = 'alert.wav'  \n",
    "\n",
    "\n",
    "drowsy_start_time = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture image\")\n",
    "        break\n",
    "\n",
    "    results = model(frame)\n",
    "    results.print()\n",
    "\n",
    "    drowsy_detected = False\n",
    "    for *box, conf, cls in results.xyxy[0]:\n",
    "        if int(cls) == 17:  \n",
    "            drowsy_detected = True\n",
    "            break\n",
    "\n",
    "    if drowsy_detected:\n",
    "        if drowsy_start_time is None:\n",
    "            drowsy_start_time = time.time()\n",
    "        elif time.time() - drowsy_start_time > DROWSY_THRESHOLD:\n",
    "            print(\"Playing alert sound now!\")  \n",
    "            play_alert_sound()  \n",
    "    else:\n",
    "        drowsy_start_time = None  \n",
    "\n",
    "\n",
    "    rendered_frame = np.squeeze(results.render())\n",
    "    cv2.imshow('Webcam - YOLOv5', rendered_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
